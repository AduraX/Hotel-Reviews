{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrapping and EDA of Hotel Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "$\\underline{TripAdvisor:}$ Every review of a Hotel includes numerical ratings. When leaving a review at Trip Advisor a reviewer gives a total score (integers from 1-5) and then has the option to rate the hotel on some certain attributes. We will use 6 of those attributes: Value, Location, Sleep Quality, Rooms, Cleanliness and Service (also integers from 1-5).\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup \n",
    "import os, shutil\n",
    "from datetime import datetime\n",
    "sep = \"~\"\n",
    "dtfmt = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "def hotel_details(soup_Page, city2):\n",
    "    hotel_info = \"\"\n",
    "    hotel_Page = soup_Page.find_all(\"div\", {\"class\": \"listing_rating\"}) \n",
    "    \n",
    "    for hotel_details in hotel_Page:  \n",
    "        hotel_rating = hotel_details.find(\"span\")\n",
    "        if hotel_rating != None: hotel_rating = hotel_rating['alt'][0]\n",
    "        else: hotel_rating = \"nan\"\n",
    "        hotel_url = hotel_details.find(\"a\")\n",
    "        if hotel_url != None:\n",
    "            Review_No = hotel_url.find(text=True)\n",
    "            Review_No = Review_No.split(\" \")[0]\n",
    "            hotel_url = hotel_url['href']     \n",
    "            hotel_url_parts = hotel_url.split(\"-\")  \n",
    "            head_url = hotel_url_parts[0] + \"-\" + hotel_url_parts[1] + \"-\" +  hotel_url_parts[2] + \"-\" + hotel_url_parts[3] + \"-\" \n",
    "            tail_url = hotel_url_parts[4] + \"-\" + hotel_url_parts[5]           \n",
    "            #id[2] + sep + name[4]     \n",
    "            hotel_detail = hotel_url_parts[2] + sep + hotel_url_parts[4] + sep + head_url + sep + tail_url + sep + hotel_rating + sep + Review_No\n",
    "            hotel_info = hotel_info + hotel_detail + \"\\n\"\n",
    "    hotel_file = open(city2 + \"/\" + city2 + \"_hotel_file.mcsv\", \"a+\")\n",
    "    hotel_file.write(hotel_info)\n",
    "    hotel_file.close()\n",
    "\n",
    "def hotel_Urls(base_urlx, sub_urlx, cityx):\n",
    "    soup_Page = BeautifulSoup(urlopen(base_urlx + sub_urlx), 'lxml')\n",
    "    div = soup_Page.find('div', {'class': 'unified pagination standard_pagination'})\n",
    "    if div.find(\"span\", {'class': 'nav next ui_button disabled'}) != None: # Last page\n",
    "        hotel_details(soup_Page, cityx)\n",
    "    elif div.find('span', {'class': 'nav previous ui_button disabled'})!=None: # First page\n",
    "        hotel_details(soup_Page, cityx)\n",
    "        urlmen = div.find('a', href = True)\n",
    "        urlmen = urlmen['href']\n",
    "        hotel_Urls(base_urlx, urlmen, cityx)\n",
    "    else:\n",
    "        hotel_details(soup_Page, cityx)\n",
    "        urlmen = div.find_all('a', href = True)\n",
    "        urlmen = urlmen[1]['href']\n",
    "        hotel_Urls(base_urlx, urlmen, cityx)\n",
    "\n",
    "def hotel_review(page_url):\n",
    "    page_review_string = \"\"\n",
    "    page_review = \"\"\n",
    "    soup = BeautifulSoup(urlopen(page_url), \"lxml\")\n",
    "    \n",
    "    #find all reviews on page and prepare to extract urls\n",
    "    reviews_onpage = soup.find_all(\"div\", {\"class\": \"reviewSelector\"})\n",
    "    review_urls = []\n",
    "    #extract urls from each review and get a list of review urls\n",
    "    for review in reviews_onpage:\n",
    "        review_url = review.find('a', href = True)\n",
    "        review_id = review['id']\n",
    "        if str(type(review_url)) != \"<type 'NoneType'>\":\n",
    "            review_url = review_url['href']\n",
    "            curr_review = {'id' : review_id, 'url' : review_url}\n",
    "            review_urls.append(curr_review)\n",
    "     \n",
    "    #begin processing reviews\n",
    "    for url in review_urls:\n",
    "        #construct url and request html\n",
    "        soup = BeautifulSoup(urlopen(base_url + url['url']), \"lxml\")\n",
    "        \n",
    "        highlight_review = soup.find(\"div\", {\"id\" : url['id']})        \n",
    "        if highlight_review is not None:\n",
    "            title = body = rati = value = locat = sleep = rooms = clean = servi = other = \"nan\"\n",
    "            \n",
    "            review_title  = highlight_review.find(\"div\", {\"property\": \"name\"})  \n",
    "            if review_title != None: title = review_title.getText()\n",
    "                \n",
    "            review_rating = highlight_review.find(\"div\", {\"class\": \"rating reviewItemInline\"})\n",
    "            if review_rating != None: \n",
    "                review_rating = review_rating.find(\"img\")  \n",
    "                if review_rating != None: rati = review_rating['alt'][0]\n",
    "                    \n",
    "            review_body = highlight_review.find(\"p\", {\"property\": \"reviewBody\"})\n",
    "            if review_body != None: \n",
    "                body =  review_body.getText(separator=' ') \n",
    "                body = body.replace('\\n', '').replace('\\r', '')\n",
    "\n",
    "            quality_ratings = highlight_review.find_all(\"li\", {\"class\": \"recommend-answer\"})\n",
    "            if quality_ratings != None:  \n",
    "                for rating in quality_ratings:\n",
    "                    description = rating.find(\"div\", {\"class\": \"recommend-description\"})\n",
    "                    description = description.find(text = True)\n",
    "                    score = rating.find(\"span\")            \n",
    "                    score = score['alt']\n",
    "                    if   description == \"Value\":    value = score[0]\n",
    "                    elif description == \"Location\": locat = score[0]\n",
    "                    elif description == \"Sleep Quality\": sleep = score[0]\n",
    "                    elif description == \"Rooms\": rooms = score[0]\n",
    "                    elif description == \"Cleanliness\": clean = score[0]\n",
    "                    elif description == \"Service\": servi = score[0]\n",
    "                    else: other = score[0]\n",
    "                    \n",
    "            page_review = url['id'] + sep + title + sep + body + sep + rati + sep \\\n",
    "                        + value + sep + locat + sep + sleep + sep + rooms + sep + clean + sep + servi + sep + other\n",
    "            page_review_string = page_review_string + page_review + \"\\n\"\n",
    "    return(page_review_string)\n",
    "\n",
    "\n",
    "def hotel_run(base_urls, sub_urls, citys, cutNo_hotels, cutNo_reviews):\n",
    "    timeStart = datetime.strptime(datetime.now().strftime(dtfmt), dtfmt)\n",
    "    print(\"\\n******* Starting time[\" + str(timeStart) + \"] Scraping reviews for \" + str(cutNo_hotels) + \" hotels ******************\")    \n",
    "   # if os.path.exists(citys): shutil.rmtree(citys)\n",
    "   # os.makedirs(citys)\n",
    "   # hotel_Urls(base_urls, sub_urls, citys)\n",
    "    \n",
    "    hotel_df = pd.read_csv(citys + \"/\" + citys + \"_hotel_file.mcsv\", sep=\"~\", header=None, names = ['id', 'name', 'urlh', 'urlt', 'rat', 'reno'])\n",
    "    hotel_df.drop_duplicates(['id'], inplace=True)\n",
    "    hotel_df.reset_index(inplace=True)\n",
    "    \n",
    "    for index, row in hotel_df.iterrows():\n",
    "        timeIndex = datetime.strptime(datetime.now().strftime(dtfmt), dtfmt) \n",
    "        output_string = \"\"\n",
    "        hotel_name = row['name']\n",
    "        head_urls = row['urlh']\n",
    "        tail_urls = row['urlt']\n",
    "        no_review = int(row['reno'].replace(',','')) \n",
    "        if no_review > cutNo_reviews: no_review = cutNo_reviews\n",
    "        _or_value = 0\n",
    "        \n",
    "        if index > cutNo_hotels: # cutoff number of hotels to study\n",
    "            timeEnd = datetime.strptime(datetime.now().strftime(dtfmt), dtfmt)\n",
    "            print(\"*********** Finished with used time[\" + str((timeStart - timeEnd)/60) + \" mins] ********************************\")\n",
    "            break \n",
    "            \n",
    "        print(\"\\tStarting time[\" + str(timeIndex) + \"] \" + str(index) + \": Scraping \" + str(no_review) + \" reviews of \" + hotel_name) \n",
    "        while (_or_value < no_review):\n",
    "            if _or_value == 0: _or = \"\"\n",
    "            else:  _or = \"or\" + str(_or_value) + \"-\"\n",
    "            reviewpg_url = base_urls + head_urls + _or + tail_urls \n",
    "            output_string = output_string + hotel_review(reviewpg_url)\n",
    "            _or_value = _or_value + 10   \n",
    "        review_file = open(citys + \"/\" + hotel_name + \"-review.mcsv\", \"a+\", encoding=\"utf-8\") \n",
    "        review_file.write(output_string)\n",
    "        review_file.close()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******* Starting time[2017-04-28 00:59:32] Scraping reviews for 40 hotels ******************\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d76fc95aac88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msub_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"/Hotels-g255057-Canberra_Australian_Capital_Territory-Hotels.html\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Canberra\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhotel_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutNo_hotel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutNo_review\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-705aca3619f8>\u001b[0m in \u001b[0;36mhotel_run\u001b[0;34m(base_urls, sub_urls, citys, cutNo_hotels, cutNo_reviews)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mhead_urls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'urlh'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mtail_urls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'urlt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mno_review\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reno'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mno_review\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mcutNo_reviews\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mno_review\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcutNo_reviews\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0m_or_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "cutNo_hotel = 40\n",
    "cutNo_review = 50\n",
    "base_url = \"http://www.tripadvisor.com.au\"\n",
    "sub_url = \"/Hotels-g255057-Canberra_Australian_Capital_Territory-Hotels.html\"\n",
    "city = \"Canberra\"\n",
    "hotel_run(base_url, sub_url, city, cutNo_hotel, cutNo_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******* Starting time[2017-04-27 19:18:27] Scraping reviews for 200 hotels ******************\n",
      "\tStarting time[2017-04-27 19:18:27] 0: Scraping 50 reviews of Radisson_Blu_Plaza_Hotel_Sydney\n",
      "\tStarting time[2017-04-27 19:20:10] 1: Scraping 50 reviews of The_Great_Southern_Hotel\n",
      "\tStarting time[2017-04-27 19:21:58] 2: Scraping 50 reviews of Travelodge_Hotel_Sydney\n",
      "\tStarting time[2017-04-27 19:23:36] 3: Scraping 50 reviews of Hotel_Bondi\n",
      "\tStarting time[2017-04-27 19:25:16] 4: Scraping 50 reviews of Manly_Paradise_Motel_Apartments\n",
      "\tStarting time[2017-04-27 19:26:55] 5: Scraping 50 reviews of Leisure_Inn_Sydney_Central\n",
      "\tStarting time[2017-04-27 19:28:41] 6: Scraping 50 reviews of Waldorf_Sydney_Central_Serviced_Apartments\n",
      "\tStarting time[2017-04-27 19:30:14] 7: Scraping 50 reviews of Oaks_Hyde_Park_Plaza\n",
      "\tStarting time[2017-04-27 19:31:50] 8: Scraping 50 reviews of Song_Hotel_Sydney\n",
      "\tStarting time[2017-04-27 19:33:38] 9: Scraping 50 reviews of Metro_Apartments_On_Darling_Harbour\n",
      "\tStarting time[2017-04-27 19:35:23] 10: Scraping 50 reviews of Annam_Apartments\n",
      "\tStarting time[2017-04-27 19:37:04] 11: Scraping 50 reviews of The_Mercantile_Hotel\n",
      "\tStarting time[2017-04-27 19:38:26] 12: Scraping 50 reviews of Manly_Surfside_Apartments\n",
      "\tStarting time[2017-04-27 19:40:04] 13: Scraping 50 reviews of Adara_Camperdown\n",
      "\tStarting time[2017-04-27 19:41:47] 14: Scraping 50 reviews of APX_World_Square\n",
      "\tStarting time[2017-04-27 19:43:24] 15: Scraping 50 reviews of Ovolo_Woolloomooloo\n",
      "\tStarting time[2017-04-27 19:45:10] 16: Scraping 50 reviews of Manor_House_Boutique_Hotel_Sydney\n",
      "\tStarting time[2017-04-27 19:46:35] 17: Scraping 50 reviews of Oaks_Goldsbrough_Apartments\n",
      "\tStarting time[2017-04-27 19:48:09] 18: Scraping 50 reviews of Valentine_On_George\n",
      "\tStarting time[2017-04-27 19:49:51] 19: Scraping 50 reviews of Waldorf_Apartment_Hotel_Sydney\n",
      "\tStarting time[2017-04-27 19:51:24] 20: Scraping 50 reviews of Sydney_Hotel_CBD\n",
      "\tStarting time[2017-04-27 19:53:07] 21: Scraping 50 reviews of APX_Apartments_Darling_Harbour\n",
      "\tStarting time[2017-04-27 19:54:46] 22: Scraping 50 reviews of Hotel_Palisade\n",
      "\tStarting time[2017-04-27 19:56:32] 23: Scraping 50 reviews of Hotel_Ravesis\n",
      "\tStarting time[2017-04-27 19:58:05] 24: Scraping 50 reviews of Abey_Hotel\n",
      "\tStarting time[2017-04-27 19:59:49] 25: Scraping 50 reviews of The_Savoy_Double_Bay_Hotel\n",
      "\tStarting time[2017-04-27 20:01:30] 26: Scraping 50 reviews of Napoleon_on_Kent\n",
      "\tStarting time[2017-04-27 20:03:16] 27: Scraping 17 reviews of Sydney_Boutique_Hotel\n",
      "\tStarting time[2017-04-27 20:03:43] 28: Scraping 50 reviews of Song_Hotel_Redfern\n",
      "\tStarting time[2017-04-27 20:05:10] 29: Scraping 50 reviews of Ibis_budget_Sydney_East\n",
      "\tStarting time[2017-04-27 20:06:37] 30: Scraping 50 reviews of Hotel_Coronation\n",
      "\tStarting time[2017-04-27 20:08:12] 31: Scraping 50 reviews of Glasgow_Arms_Hotel\n",
      "\tStarting time[2017-04-27 20:09:56] 32: Scraping 50 reviews of Mercure_Sydney\n",
      "\tStarting time[2017-04-27 20:11:45] 33: Scraping 50 reviews of Coogee_Bay_Hotel\n",
      "\tStarting time[2017-04-27 20:13:18] 34: Scraping 50 reviews of Cambridge_Lodge_Guest_House\n",
      "\tStarting time[2017-04-27 20:14:47] 35: Scraping 50 reviews of Park_Regis_City_Centre\n",
      "\tStarting time[2017-04-27 20:16:34] 36: Scraping 50 reviews of Best_Western_Haven_Glebe\n",
      "\tStarting time[2017-04-27 20:18:19] 37: Scraping 50 reviews of Woolbrokers_Hotel\n",
      "\tStarting time[2017-04-27 20:20:06] 38: Scraping 19 reviews of Coogee_Bay_Hotel_Pub_Style_Rooms\n",
      "\tStarting time[2017-04-27 20:20:44] 39: Scraping 16 reviews of Camperdown_Suites\n",
      "\tStarting time[2017-04-27 20:21:05] 40: Scraping 50 reviews of Seasons_Harbour_Plaza\n",
      "\tStarting time[2017-04-27 20:22:32] 41: Scraping 43 reviews of Darlo_Bar_Darlinghurst\n",
      "\tStarting time[2017-04-27 20:24:00] 42: Scraping 6 reviews of Park_Lodge_Hotel\n",
      "\tStarting time[2017-04-27 20:24:13] 43: Scraping 50 reviews of Ibis_Budget_St_Peters\n",
      "\tStarting time[2017-04-27 20:25:45] 44: Scraping 50 reviews of Kirketon_Hotel\n",
      "\tStarting time[2017-04-27 20:27:20] 45: Scraping 37 reviews of Beach_Road_Hotel\n",
      "\tStarting time[2017-04-27 20:28:18] 46: Scraping 50 reviews of Ultimate_Apartments_Bondi_Beach\n",
      "\tStarting time[2017-04-27 20:29:40] 47: Scraping 23 reviews of The_Crest_Hotel\n",
      "\tStarting time[2017-04-27 20:30:19] 48: Scraping 7 reviews of Balmain_Lodge\n",
      "\tStarting time[2017-04-27 20:30:35] 49: Scraping 8 reviews of Gazebo_Hotel\n",
      "\tStarting time[2017-04-27 20:30:50] 50: Scraping 2 reviews of Kingsview\n",
      "\tStarting time[2017-04-27 20:30:55] 51: Scraping 31 reviews of Sydney_Lodge_Motel\n",
      "\tStarting time[2017-04-27 20:32:17] 52: Scraping 50 reviews of Wynyard_Hotel\n",
      "\tStarting time[2017-04-27 20:33:46] 53: Scraping 1 reviews of Saville_Park_Suites_Sydney\n",
      "\tStarting time[2017-04-27 20:33:50] 54: Scraping 6 reviews of Forest_Lodge\n",
      "\tStarting time[2017-04-27 20:34:02] 55: Scraping 50 reviews of Seasons_Darling_Harbour\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 11001] getaddrinfo failed>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32mc:\\users\\adura\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m                 \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\adura\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\adura\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\adura\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body)\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\adura\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\adura\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\adura\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    848\u001b[0m         self.sock = self._create_connection(\n\u001b[0;32m--> 849\u001b[0;31m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[1;32m    850\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\adura\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSOCK_STREAM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\adura\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0c9dcf880378>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msub_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"/Hotels-g255060-Sydney_New_South_Wales-Hotels.html\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Sydney\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhotel_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutNo_hotel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutNo_review\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-705aca3619f8>\u001b[0m in \u001b[0;36mhotel_run\u001b[0;34m(base_urls, sub_urls, citys, cutNo_hotels, cutNo_reviews)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[0m_or\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"or\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_or_value\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"-\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mreviewpg_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_urls\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mhead_urls\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0m_or\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtail_urls\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0moutput_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_string\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mhotel_review\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviewpg_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0m_or_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_or_value\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mreview_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcitys\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mhotel_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"-review.mcsv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"a+\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-705aca3619f8>\u001b[0m in \u001b[0;36mhotel_review\u001b[0;34m(page_url)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreview_urls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[1;31m#construct url and request html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_url\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lxml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mhighlight_review\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"id\"\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\adura\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\adura\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\adura\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 484\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\adura\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\adura\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0mhttp_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\adura\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1254\u001b[0m                 \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 11001] getaddrinfo failed>"
     ]
    }
   ],
   "source": [
    "cutNo_hotel = 200\n",
    "cutNo_review = 50\n",
    "base_url = \"http://www.tripadvisor.com.au\"\n",
    "sub_url = \"/Hotels-g255060-Sydney_New_South_Wales-Hotels.html\"\n",
    "city = \"Sydney\"\n",
    "hotel_run(base_url, sub_url, city, cutNo_hotel, cutNo_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cutNo_hotel = 40\n",
    "cutNo_review = 100\n",
    "base_url = \"http://www.tripadvisor.com.au\"\n",
    "sub_url = \"/Hotels-g255100-Melbourne_Victoria-Hotels.html\"\n",
    "city = \"Melbourne\"\n",
    "hotel_run(base_url, sub_url, city, cutNo_hotel, cutNo_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cutNo_hotel = 40\n",
    "cutNo_review = 100\n",
    "base_url = \"http://www.tripadvisor.com.au\"\n",
    "sub_url = \"/Hotels-g255068-Brisbane_Brisbane_Region_Queensland-Hotels.html\"\n",
    "city = \"Brisbane\"\n",
    "hotel_run(base_url, sub_url, city, cutNo_hotel, cutNo_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cutNo_hotel = 30\n",
    "cutNo_review = 50\n",
    "base_url = \"http://www.tripadvisor.com.au\"\n",
    "sub_url = \"/Hotels-g255103-Perth_Greater_Perth_Western_Australia-Hotels.html\"\n",
    "city = \"Perth\"\n",
    "hotel_run(base_url, sub_url, city, cutNo_hotel, cutNo_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cutNo_hotel = 30\n",
    "cutNo_review = 50\n",
    "base_url = \"http://www.tripadvisor.com.au\"\n",
    "sub_url = \"/Hotels-g255097-Hobart_Greater_Hobart_Tasmania-Hotels.html\"\n",
    "city = \"Hobart\"\n",
    "hotel_run(base_url, sub_url, city, cutNo_hotel, cutNo_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cutNo_hotel = 30\n",
    "cutNo_review = 50\n",
    "base_url = \"http://www.tripadvisor.com.au\"\n",
    "sub_url = \"/Hotels-g255066-Darwin_Top_End_Northern_Territory-Hotels.html\"\n",
    "city = \"Darwin\"\n",
    "hotel_run(base_url, sub_url, city, cutNo_hotel, cutNo_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
